In the evolving landscape of Big Data Engineering and ETL processes, this study takes a deep dive into efficiency, leveraging the MIMIC-III Clinical Database as a sturdy foundation. Our primary goal is to explore and enhance the efficiency of Big Data Engineering and ETL processes in the healthcare domain.
Key Objectives:
Investigate efficient practices in Big Data Engineering and ETL processes.
Utilize the MIMIC-III Clinical Database as a foundational dataset.
Approaches: Our methodology involves meticulous experimentation with a sample dataset, emphasizing the advantages of a comprehensive set of technologies:
Technologies:
PySpark: Deployed for distributed computing.
Docker: Containerization for streamlined deployment.
Docker Compose: Orchestrating multi-container applications.
Python: Utilized for scripting and data manipulation.
Pandas: Employed for data manipulation and analysis.
PostgreSQL: Used for efficient data storage and retrieval.
Major Findings:
Unveiling significant time efficiency gains with PySpark in distributed computing.
Highlighting the benefits of PySpark in Docker containerized applications:
Enhanced scalability and flexibility.
Simplified deployment and reproducibility.
Efficient resource utilization within containerized environments.
Strategic Integration: Docker containers and Docker Compose are strategically integrated, showcasing their pivotal role in enhancing scalability and reproducibility of the ETL pipeline.
Practical Implications: This poster presentation encapsulates pivotal insights, emphasizing the practical benefits of deploying PySpark within Docker containerized applications using Docker Compose for streamlined Big Data Engineering and ETL processes within the healthcare domain.
